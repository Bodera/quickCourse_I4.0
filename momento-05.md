## Big Data
Neste módulo, você conhecerá o conceito de Big Data, suas características e aplicações; e entenderá como o uso dessa tecnologia possibilita que as empresas se tornem ágeis. Além disso, conhecerá como surgiram a Inteligência Artificial e o processo de análise de dados.  

Espera-se que ao final desse módulo, você tenha entendido como Big Data, IoT, Computação em Nuvem e Inteligência Artificial podem ser utilizados para beneficiar a indústria, o setor de serviços e a sociedade

### Definição
O contexto do Big Data dá-se pelo enorme volume de dados que vem sido produzido nos últimos anos.  
Para se ter uma ideia da velocidade na geração dos dados, é sabido que 90% dos dados disponíveis hoje foram gerados nos últimos dois anos. Ou seja, a sociedade atual está gerando uma quantidade de informação muito superior à gerada por toda a humanidade ao longo dos séculos.  

A Internet é uma das principais fontes de dados. Globalmente, a web recebe os mais diversos formatos de dados, de artigos científicos a publicações nas redes sociais, nos formatos de texto, imagem, vídeo e áudio.  

Big Data não deve ser entendido apenas pelo volume de dados. O fator principal, para a indústria, no uso dessa tecnologia é a capacidade de processar e avaliar as informações relevantes, pois de nada serve possuir grandes volumes de dados se não puder fazer uso deles. É preciso extrair conhecimentos úteis e valiosos, de modo que se faz necessário o uso de ferramentas e técnicas que irão dar suporte a estratégias de competitividade a partir da inferência de padrões, processando um grande volume de dados, em diversos formatos, em velocidade adequada.  

O Big Data possui 5 características fortes, que sustentam o conceito.  
* __Volume__   
Atém-se à quantidade de dados cada vez maior que está sendo gerada e/ou consumida.  
O desafio de armazenar e consequentemente o de recuperar um grande volume de dados. Por meio de soluções computacionais capazes de armazenar volumes massivos de dados e indexá-los para agilizar a identificação e recuperação.  
Além disso, o custo para o armazenagem dos dados está mais barato. De acordo com a revista Computer World, em 1970, por exemplo, armazenar 1 gigabyte de dados custava $185.000 (cento e oitenta e cinco mil dólares).  
Essa mesma quantidade, em 2017, estava sendo ofertada por $0.02 (2 centavos de dólar).  
* __Velocidade__  
Refere-se à velocidade com que os dados são gerados e/ou recuperados.  
A velocidade dos dados está ligada a taxa de geração, mas também à taxa de consumo. Para a indústria, essa velocidade é um desafio de Big Data, pois é preciso desenvolver mecanismos capazes de processar esses dados em tempo real.  
* __Variedade__  
Refere-se aos mais diversos formatos de dados. No início da era digital, buscou-se fazer uso de dados estruturados, como em modelos de banco de dados relacionais.  
Porém, com o avanço da Internet, e a proliferação das redes sociais, passamos a utilizar dados não-estruturados, como vídeos, imagens, textos (mensagens).  
Processar tais formatos de dados requer o desenvolvimento de tecnologias especializadas.   
* __Veracidade__  
Refere-se à obtenção de dados verídicos. O conceito de velocidade está alinhado com o conceito de veracidade, pois os dados devem ser analisados em tempo real.  
Ou seja, os dados devem ser analisados de forma constante para dar veracidade à análise.  
* __Valor__  
Refere-se ao valor agregado ao processo: coleta, armazenamento e análise dados. Em outras palavras, o processo de análise de dados pode gerar novos conhecimentos e valor para a indústria.   

Visando obter melhor proveito do Big Data, o tratamento de dados é uma atividade  formada por métodos de gestão, técnicas de processamento, mineração de dados e descoberta de conhecimento, inclusive com o uso da Inteligência Artificial. A seguir um roteiro proposto do processo de Big Data.    
1. __Estabelecer questionamentos__  
A primeira coisa a fazer é estabelecer as perguntas para as quais buscaremos respostas. Normalmente, essa formulação acontece em dois estágios: em Adquirir Dados (2) e em Realizar modelo (4), no qual as perguntas são refinadas.  

2. __Adquirir dados__  
Nessa etapa, são consultadas diversas fontes de dados a fim de estabelecer os elementos da análise.  

3. __Limpar dados__  
Essa etapa consiste na aplicação de técnicas de limpeza de dados (data cleaning), com o objetivo de detectar e sanar imperfeições nos dados coletados.  
Isso porque nem todos os dados coletados são necessários para responder ao questionamento estabelecido. Pois podem conter informações irrelevantes, duplicadas ou em formato inapropriado para o modelo.  

4. __Realizar modelo__  
Se os dados coletados apresentarem formato adequado para a resolução do problema, serão transformados em uma semântica que permita ao analista de dados proceder com a análise. Nesse estágio, os dados são agrupados, formatados e/ou transformados para os métodos analíticos, normalmente empregando técnicas de aprendizagem de máquina.  

5. __Analisar dados__ 
Esse é considerado o passo fundamental do processo. É nesse estágio que, com uso de técnicas estatísticas, de manipulação de dados e de aprendizado de máquina, os dados são transformados em conhecimento.  

6. __Apresentar__  
Os resultados dos métodos analíticos são compostos por diversos elementos e a sua compreensão não é imediata e de fácil assimilação. Por isso, são utilizadas técnicas de visualização para representar o novo conhecimento de uma maneira coerente e de fácil compreensão.  

7. __Analisar resultados__  
Nesse momento, as considerações sobre os resultados obtidos são apresentadas por meio de um conjunto de relatórios que descrevem o processo realizado e as descobertas geradas ao longo das etapas anteriores.  

8. __Refinar o problema__  
Normalmente, o processo de Big Data Analytics busca a melhoria contínua e o aperfeiçoamento das análises. Dessa forma, nesse estágio o problema é refinado, seja para novos questionamentos ou para maior detalhamento do problema abordado.  

##### Inteligência artificial
Na década de 1950, pesquisadores descobriram que ao descrever as ações humanas por meio de uma série de deduções e lógicas matemáticas, seria possível programar o computador para realizar estas operações, simulando a inteligência humana.  

A esta linha de pesquisa deu-se o nome de Inteligência Artificial (AI, do inglês Artificial Intelligence), que desde sua criação tem se buscado fazer com que os computadores simulem a forma de pensar e agir dos seres humanos, modelando elementos como ações reativas e até sentimentos.  

Para melhor compreender os objetivos da Inteligência Artificial, conheça o teste proposto em 1950 por Alan Turing, conhecido com o pai da computação.  

No teste de Turing, um humano (interrogador) utiliza um teclado para fazer perguntas a duas entidades ocultas: outro humano e um computador.  

As respostas são fornecidas pelo computador e pelo humano, sendo que o computador é programado para simular o papel do humano, enquanto que o humano deve responder de maneira a confirmar a sua condição. Cabe ao interrogador distinguir qual  das respostas foi enviada pelo humano.  

A Inteligência Artificial do computador será aprovada se o interrogador não conseguir distinguir quais respostas foram fornecidas pelo humano e quais foram fornecidas pelo computador.  

Para Turing, o comportamento inteligente de uma máquina é expresso pela habilidade de obter o desempenho humano em todas as tarefas cognitivas, podendo, assim, enganar um interrogador humano. Nenhum computador foi aprovado nesse teste, pois, para isso, seria necessário uma máquina com diversas habilidades, dentre as quais destacamos:

* Processamento de linguagem natural de modo a permitir que uma máquina compreenda e se comunique em uma linguagem humana.  
* Representação do conhecimento, permitindo ao computador armazenar informações antes e/ou durante o interrogatório.  
* Raciocínio automatizado para utilizar a informação armazenada para responder às questões, assim como obter novas conclusões a partir dos fatos adicionados a cada interrogatório.  
* Aprendizado de máquina para se adaptar às circunstâncias, detectar e extrapolar padrões.  
* Visão computacional para reconhecer possíveis imagens ou objetos utilizados no interrogatório.  
* Robótica para atuar na percepção e para manipular objetos.  

```
 Essa tecnologia tem sido adotada por muitas empresas para tratar sugestões, informações, reclamações e dúvidas de seus clientes.  

 Exemplos de Inteligência Artificial são as assistentes virtuais das empresas Google (Google Assistant), da Apple (Siri) e da Amazon (Alexa).  
```

### Mineração de dados
Entretanto desenvolver todas essas habilidades requer conhecimento provenientes de múltiplas áreas. Dessa forma, o que se viu ao longo da história da Inteligência Artificial foi o desenvolvimento isolado de cada habilidade, sem ter o teste de Turing como foco.  

Em relação ao Big Data, a Inteligência Artificial contribuiu com a construção de modelos computacionais para análise e descoberta de padrões em grandes conjuntos de dados. A área da Inteligência Artificial que mais se relaciona a tais processos é denominada Aprendizagem de Máquina, com a subárea Mineração de Dados (em inglês, Data Mining).  

Por meio das técnicas de mineração é possível obter dados, normalmente, na forma de regras lógicas ou predições computacionais, que irão subsidiar um processo de tomada de decisão. Exemplo disso são as aplicações que buscam fazer previsões (denominadas modelagens preditivas), descobrir novos padrões ou associações (denominadas modelagens descritivas), refinar agrupamentos por critérios de semelhança ou compreender anomalias de comportamento.  

#### Associação
#### Classificação
#### Agrupamento

### Big data na indústria 4.0
Big Data e Inteligência Artificial podem ser utilizados no contexto da Indústria 4.0 por meio da leitura de dados gerados por dispositivos e sensores, bases históricas de downtime, além de alertas de manutenção preventiva.  

Os dados coletados a partir de dispositivos e sensores podem ser utilizados em processos analíticos, integrados com bases externas, ou utilizados por algoritmos de mineração de dados. Os algoritmos utilizados podem fornecer predições ou novos conhecimentos que auxiliarão na redução de defeitos, na otimização da matéria-prima e da energia elétrica, assim como para definir a melhor configuração do ambiente produtivo para atender flutuações do mercado.  

<figure>
  <img src="/assets/sena-big-data.png" alt="Minha Figura">	
  <figcaption>Etapas do processo de aplicação do Big Data na Indústria 4.0</figcaption>
</figure>

1. Os dados proveniente de sensores em equipamentos são armazenados e processados com uso de tecnologias de Big Data e Computação em Nuvem. No armazenamento, é importante observar a segurança de dados e informações.   

2. Os dados passam por um processo analítico, com o uso de inteligência artificial, e são incorporados dados de outras fontes como clientes e fornecedores, por exemplo.  

3. A análise avançada gera novas informações e conhecimentos, os chamados dados inteligentes (_Smart Data_).  

4. Com esse processo, há economia de insumos, redução dos defeitos e adaptação à demanda, graças a capacidade analítica que o ambiente proporciona.   

Esse processo ajuda a empresa a ser ágil na tomada de decisão em resposta aos eventos da planta e às demandas do mercado, e a aprender com as ações tomadas, as reações de sua cadeia de valor e decisões tomadas no processo.

### Case
A indústria automotiva vem se beneficiando das novas tecnologias tanto para melhorar a experiência de condução do motorista como para otimizar os processos de produção. Por exemplo, sensores instalados no veículo coletam e enviam dados sobre o desempenho do automóvel, tanto para o motorista, como para o fabricante do veículo.  

O fabricante pode usar os dados coletados para avisar o motorista sobre a necessidade de manutenção no veículo, com sugestão de data e local para essa manutenção. Ao mesmo tempo, o fabricante aciona o concessionário mais próximo do cliente a fim de que a oficina se prepare para realizar a manutenção do veículo.   

Os dados coletados ainda podem ser usados para otimizar a linha de produção, com peças ou acessórios mais demandados ou para aprimorar os projetos de novas versões do veículo ou de outros modelos. Com isso, o fabricante, o motorista e o concessionário se beneficiam do uso da tecnologia.

### Quiz
Como você viu, a empresa pode se beneficiar do processo de Big Data Analytics para se tornar ágil na tomada de decisão em resposta aos eventos da planta e às demandas do mercado. Com relação à planta, selecione as oportunidades decorrentes da análise de dados:  

a.[X] Identificar os períodos de parada.
b.[] Aumentar a mão de obra especializada.
c.[X] Identificar o consumo de energia.
d.[] Aprimorar o aprendizado de máquinas.
e.[X] Identificar a necessidade de manutenção preditiva.
f.[X] Reduzir o uso de matéria-prima e de energia.
g.[] Aumentar a aderência do produto ao mercado.
h.[X] Reduzir defeitos no produto.

### Conclusão
Nesse módulo, você conheceu o conceito de Big Data, as etapas do processo de análise de dados, no Big Data Analytics, e os conceitos de Inteligência Artificial e Mineração de Dados.  

Você viu, também, como Big Data e Inteligência Artificial podem ser utilizados no contexto da Indústria 4.0 para promover redução de defeitos, a otimização da matéria-prima e da energia elétrica, assim como para definir a melhor configuração do ambiente produtivo para atender flutuações do mercado. 